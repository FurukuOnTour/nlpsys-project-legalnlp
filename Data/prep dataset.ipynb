{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OGpath = 'D:/0-NLP code/NLP III/'\n",
    "path = 'D:/0-NLP code/NLP III/FlukeFiles/'\n",
    "path2 = 'D:/0-NLP code/NLP III/TerFiles/'\n",
    "pathAll = 'D:/0-NLP code/NLP III/allFiles/'\n",
    "flist = os.listdir(path)\n",
    "flist2 = os.listdir(path2)\n",
    "flistAll = os.listdir(pathAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-favorable', '-other', '-partially favorable', '-unfavorable']\n"
     ]
    }
   ],
   "source": [
    "BlabelList = ['B-favorable','B-other','B-partially favorable','B-unfavorable']\n",
    "allLabelList = ['I-favorable','I-other','I-partially favorable','I-unfavorable','O','B-favorable','B-other','B-partially favorable','B-unfavorable']\n",
    "allLabelChange = ['-favorable','-other','-partially favorable','-unfavorable']\n",
    "print(allLabelChange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = []\n",
    "label = []\n",
    "\n",
    "for f in flistAll:\n",
    "    with open(pathAll+f, 'r', encoding='utf-8') as files:\n",
    "        data = files.read().strip().replace('\\n\\n','\\n').replace('\\t','\\n').split('\\n')\n",
    "        if BlabelList[0] in data:\n",
    "                text.append(''.join([x for x in data[:data.index(BlabelList[0])-1] if x not in allLabelList]))\n",
    "                label.append(BlabelList[0][2:])\n",
    "        elif BlabelList[1] in data:\n",
    "                text.append(''.join([x for x in data[:data.index(BlabelList[1])-1] if x not in allLabelList]))\n",
    "                label.append(BlabelList[1][2:])\n",
    "        elif BlabelList[2] in data:\n",
    "                text.append(''.join([x for x in data[:data.index(BlabelList[2])-1] if x not in allLabelList]))\n",
    "                label.append(BlabelList[2][2:])\n",
    "        elif BlabelList[3] in data:\n",
    "                text.append(''.join([x for x in data[:data.index(BlabelList[3])-1] if x not in allLabelList]))\n",
    "                label.append(BlabelList[3][2:])\n",
    "        else:\n",
    "                print('something went wrong with data')\n",
    "\n",
    "for word in text:\n",
    "        if len(word) < 20:\n",
    "                Windex = text.index(word)\n",
    "                text.pop(Windex)\n",
    "                label.pop(Windex)\n",
    "\n",
    "len(text) == len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "forDataFrame = {\"text\": text,\"label\": label}\n",
    "df = pd.DataFrame(forDataFrame)\n",
    "df.to_csv(OGpath+'all.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allD = pd.read_csv(OGpath+'all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partially favorable    0.365333\n",
       "unfavorable            0.296000\n",
       "favorable              0.224000\n",
       "other                  0.114667\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allD.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     375.000000\n",
       "mean     2249.282667\n",
       "std      1447.687003\n",
       "min        94.000000\n",
       "25%      1269.000000\n",
       "50%      2030.000000\n",
       "75%      2925.000000\n",
       "max      8750.000000\n",
       "Name: len, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# allD['len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(allD, train_size=0.8, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train \n",
    "train.to_csv(OGpath+'train.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev\n",
    "dev.to_csv(OGpath+'dev.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL = ''\n",
    "# for f in flist:\n",
    "#     with open(path+f, 'r', encoding='utf-8') as files:\n",
    "#         a = files.read().strip().replace('\\n\\n','\\n')\n",
    "#         ALL += a + '\\n\\n'\n",
    "\n",
    "# with open(path+'allFlukeFile.tsv', 'w') as NF:\n",
    "#     NF.write(ALL)\n",
    "\n",
    "# ALL = ''\n",
    "# for f in flist2:\n",
    "#     with open(path2+f, 'r', encoding='utf-8') as files:\n",
    "#         a = files.read().strip().replace('\\n\\n','\\n')\n",
    "#         ALL += a + '\\n\\n'\n",
    "\n",
    "# with open('D:/0-NLP code/NLP III/'+'allTerFile.tsv', 'w', encoding='utf-8') as NF:\n",
    "#     NF.write(ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(flistAll, train_size=0.8, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n",
      "304\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "## check percentage of data\n",
    "print(len(flistAll))\n",
    "print(len(train))\n",
    "print(len(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-favorable', '-other', '-partially favorable', '-unfavorable']\n"
     ]
    }
   ],
   "source": [
    "BlabelList = ['B-favorable','B-other','B-partially favorable','B-unfavorable']\n",
    "allLabelList = ['I-favorable','I-other','I-partially favorable','I-unfavorable','O','B-favorable','B-other','B-partially favorable','B-unfavorable']\n",
    "allLabelChange = ['-favorable','-other','-partially favorable','-unfavorable']\n",
    "print(allLabelChange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make train and dev set for verdict\n",
    "ALL = ''\n",
    "for f in train:\n",
    "    with open(pathAll+f, 'r', encoding='utf-8') as files:\n",
    "        a = files.read().strip().replace('\\n\\n','\\n')\n",
    "        for labels in allLabelChange:\n",
    "            a = a.replace(labels, '-verdict')\n",
    "        ALL += a + '\\n\\n'\n",
    "\n",
    "with open('D:/0-NLP code/NLP III/'+'trainVerdict.tsv', 'w', encoding='utf-8') as NF:\n",
    "    NF.write(ALL)\n",
    "\n",
    "ALL = ''\n",
    "for f in dev:\n",
    "    with open(pathAll+f, 'r', encoding='utf-8') as files:\n",
    "        a = files.read().strip().replace('\\n\\n','\\n')\n",
    "        for labels in allLabelChange:\n",
    "            a = a.replace(labels, '-verdict')\n",
    "        ALL += a + '\\n\\n'\n",
    "\n",
    "with open('D:/0-NLP code/NLP III/'+'devVerdict.tsv', 'w', encoding='utf-8') as NF:\n",
    "    NF.write(ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2475_970.txt.tsv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flistAll[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make train and dev set for fact to favorbility\n",
    "\n",
    "text = []\n",
    "label = []\n",
    "for f in train:\n",
    "    with open(pathAll+f, 'r', encoding='utf-8') as files:\n",
    "        data = files.read().strip().replace('\\n\\n','\\n').replace('\\t','\\n').split('\\n')\n",
    "        if BlabelList[0] in data:\n",
    "                text.append(''.join([x for x in data[:data.index(BlabelList[0])-1] if x not in allLabelList]))\n",
    "                label.append(BlabelList[0][2:])\n",
    "        elif BlabelList[1] in data:\n",
    "                text.append(''.join([x for x in data[:data.index(BlabelList[1])-1] if x not in allLabelList]))\n",
    "                label.append(BlabelList[1][2:])\n",
    "        elif BlabelList[2] in data:\n",
    "                text.append(''.join([x for x in data[:data.index(BlabelList[2])-1] if x not in allLabelList]))\n",
    "                label.append(BlabelList[2][2:])\n",
    "        elif BlabelList[3] in data:\n",
    "                text.append(''.join([x for x in data[:data.index(BlabelList[3])-1] if x not in allLabelList]))\n",
    "                label.append(BlabelList[3][2:])\n",
    "        else:\n",
    "                print('something went wrong with data')\n",
    "        # print(text)\n",
    "        # print(label)\n",
    "\n",
    "forDataFrame = {\"text\": text,\"label\": label}\n",
    "df = pd.DataFrame(forDataFrame)\n",
    "df.to_csv(OGpath+'train.csv', encoding='utf-8', index=False)\n",
    "\n",
    "text = []\n",
    "label = []\n",
    "for f in dev:\n",
    "    with open(pathAll+f, 'r', encoding='utf-8') as files:\n",
    "        data = files.read().strip().replace('\\n\\n','\\n').replace('\\t','\\n').split('\\n')\n",
    "        if BlabelList[0] in data:\n",
    "                text.append(''.join([x for x in data[:data.index(BlabelList[0])-1] if x not in allLabelList]))\n",
    "                label.append(BlabelList[0][2:])\n",
    "        elif BlabelList[1] in data:\n",
    "                text.append(''.join([x for x in data[:data.index(BlabelList[1])-1] if x not in allLabelList]))\n",
    "                label.append(BlabelList[1][2:])\n",
    "        elif BlabelList[2] in data:\n",
    "                text.append(''.join([x for x in data[:data.index(BlabelList[2])-1] if x not in allLabelList]))\n",
    "                label.append(BlabelList[2][2:])\n",
    "        elif BlabelList[3] in data:\n",
    "                text.append(''.join([x for x in data[:data.index(BlabelList[3])-1] if x not in allLabelList]))\n",
    "                label.append(BlabelList[3][2:])\n",
    "        else:\n",
    "                print('something went wrong with data')\n",
    "        # print(text)\n",
    "        # print(label)\n",
    "\n",
    "forDataFrame = {\"text\": text,\"label\": label}\n",
    "df = pd.DataFrame(forDataFrame)\n",
    "df.to_csv(OGpath+'dev.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2475/970ย่อสั้นพฤตติการณ์อย่างไรเป็นการกระทำโดยประมาททำให้ทรัพย์ผู้อื่นเสียหายขับรถทับกระจกริมถนนแตกย่อยาวทางพิจารณาได้ความว่าคนใช้โจทก์ได้เอากระจกของโจทก์แผ่นหนึ่งกว้างยาวประมาณ๒ศอกเศษไปฝึ่งแดดวางพิงไว้บ้างบาทวิถีล้ำถนนหลวงออกไปประมาณศอกเศษจำเลยจอดรถเติมน้ำมันข้างถนนบังเอิญมีรถยนต์คันหนึ่งแล่นสวนมาจำเลยจึงหักรถเข้าข้างถนนมิฉะนั้นจะโดนกันล้อหลังจึงทับกระจบแตกโจทก์จึงฟ้องเรียกค่าเสียหายจำเลยฎีกาศาลฎีกาเห็นว่าถนนหลวงไม่ใช่สถานที่สำหรับตากวางสิ่งของและจำเลยได้หลีกอันตรายซึ่งจะมีมาข้างหน้าโดยกระทันหันจำเลยไม่ควรรับผิดจึงตัดสินยืนตามศาลเดิม'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0].replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check csv data\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "datadev = pd.read_csv('dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2475/970ย่อสั้นพฤตติการณ์อย่างไรเป็นการกระทำโดยประมาททำให้ทรัพย์ผู้อื่นเสียหายขับรถทับกระจกริมถนนแตกย่อยาวทางพิจารณาได้ความว่าคนใช้โจทก์ได้เอากระจกของโจทก์แผ่นหนึ่งกว้างยาวประมาณ๒ศอกเศษไปฝึ่งแดดวางพิงไว้บ้างบาทวิถีล้ำถนนหลวงออกไปประมาณศอกเศษจำเลยจอดรถเติมน้ำมันข้างถนนบังเอิญมีรถยนต์คันหนึ่งแล่นสวนมาจำเลยจึงหักรถเข้าข้างถนนมิฉะนั้นจะโดนกันล้อหลังจึงทับกระจบแตกโจทก์จึงฟ้องเรียกค่าเสียหายจำเลยฎีกา'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38      15\n",
       "210     16\n",
       "170     16\n",
       "29      94\n",
       "42     134\n",
       "275    183\n",
       "217    190\n",
       "257    235\n",
       "116    240\n",
       "147    242\n",
       "260    246\n",
       "231    282\n",
       "92     330\n",
       "235    379\n",
       "243    394\n",
       "82     397\n",
       "111    397\n",
       "31     475\n",
       "117    509\n",
       "185    533\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'].str.len().sort_values(ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     2539/5609ย่อสั้นจำเลยไม่ได้เป็นเจ้าของที่ดินพิ...\n",
       "label                                          unfavorable\n",
       "Name: 92, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2519/248ย่อสั้น'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadev['text'].loc[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2526/321ย่อสั้นฎีกาว่าโจทก์อุทธรณ์ปัญหาข้อกฎหมายแต่ศาลอุทธรณ์กลับไปวินิจฉัยปัญหาข้อเท็จจริงที่โจทก์มิได้อุทธรณ์และในข้อหาแสดงพยานหลักฐานเท็จในการพิจารณาศาลชั้นต้นยกฟ้องโจทก์โดยปัญหาข้อกฎหมายไม่ต้องห้ามโจทก์อุทธรณ์นั้นเป็นปัญหาข้อกฎหมายแม้ศาลอุทธรณ์พิพากษายืนให้ยกฟ้องก็ตามคดีไม่ต้องห้ามฎีกาตามประมวลกฎหมายวิธีพิจารณาความอาญามาตรา220ย่อยาว'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadev['text'].loc[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
